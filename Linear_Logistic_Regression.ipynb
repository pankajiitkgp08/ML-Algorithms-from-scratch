{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code written by Pankaj and verified the logic with the blog - \n",
    "# https://towardsdatascience.com/linear-regression-from-scratch-with-numpy-implementation-finally-8e617d8e274c\n",
    "############## Steps to do \n",
    "# 1. Generate a dataset ( n rows; m features; 1 target-continuous)\n",
    "# 2. Write Cost function \n",
    "# 3. Write gradient descent function\n",
    "# 4. Write Prediction function \n",
    "# 5. Write train function\n",
    "\n",
    "# For KNN in numpy: https://towardsdatascience.com/k-nearest-neighbors-classification-from-scratch-with-numpy-cb222ecfeac1\n",
    "# For Kmeans in numpy: https://flothesof.github.io/k-means-numpy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os, csv, random\n",
    "from sklearn import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Generation\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    a = np.random.rand(5)*100 +5\n",
    "    data.append(a)\n",
    "data = np.vstack((data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression class\n",
    "class linear_reg:\n",
    "    def __init__(self):\n",
    "        self.X1 = None\n",
    "        self.y = None\n",
    "        self.W = None\n",
    "        self.num_epochs = 10\n",
    "        self.lr = 0.01\n",
    "        \n",
    "    def gradient(self):\n",
    "        n,m = self.X1.shape\n",
    "        diff = (self.y - self.__predict(self.X1)).T\n",
    "        res = np.matmul(diff, self.X1)\n",
    "        C = (-2.0/n)\n",
    "        return C*res.T\n",
    "    \n",
    "    def __train(self):\n",
    "        # Initiliaze weights\n",
    "        n,m = self.X1.shape\n",
    "        self.W = np.random.rand(m)\n",
    "        #self.W = np.array([np.random.rand() for _ in range(m)])\n",
    "        loss = []\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.W = self.W - self.lr*self.gradient()\n",
    "            curr_loss = (self.loss_func(self.y, self.__predict(self.X1)))\n",
    "            loss.append(curr_loss)\n",
    "            print (curr_loss)\n",
    "        \n",
    "    def train(self,X,y):\n",
    "        self.X1 = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "        self.y = y\n",
    "        self.__train() # Begin training\n",
    "        \n",
    "        \n",
    "    def __predict(self,X_eval):\n",
    "        #return np.dot(W, x_vector)\n",
    "        #return np.matmul(X_eval, self.W.T)\n",
    "        return X_eval@self.W.T\n",
    "    \n",
    "    def predict(self, X_temp):\n",
    "        #print (X_temp.shape)\n",
    "        temp  = np.hstack((np.ones((X_temp.shape[0],1)), X_temp))\n",
    "        #print (temp.shape)\n",
    "        return self.__predict(temp)\n",
    "    \n",
    "    def loss_func(self,y, y_hat):\n",
    "        return np.mean((y - y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[:,:-1], data[:,-1]\n",
    "model = linear_reg()\n",
    "model.train(X,y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression class\n",
    "class logistic_reg:\n",
    "    def __init__(self):\n",
    "        self.X1 = None\n",
    "        self.y = None\n",
    "        self.W = None\n",
    "        self.num_epochs = 10\n",
    "        self.lr = 0.01\n",
    "        \n",
    "    def gradient(self):\n",
    "        n,m = self.X1.shape\n",
    "        diff = (self.y - self.__predict(self.X1)).T\n",
    "        res = np.matmul(diff, self.X1)\n",
    "        C = (-1.0/n)\n",
    "        return C*res.T\n",
    "    \n",
    "    def __train(self):\n",
    "        # Initiliaze weights\n",
    "        n,m = self.X1.shape\n",
    "        self.W = np.random.rand(m)\n",
    "        #self.W = np.array([np.random.rand() for _ in range(m)])\n",
    "        loss = []\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.W = self.W - self.lr*self.gradient()\n",
    "            curr_loss = (self.loss_func(self.y, self.__predict(self.X1)))\n",
    "            loss.append(curr_loss)\n",
    "            print (curr_loss)\n",
    "        \n",
    "    def train(self,X,y):\n",
    "        X = (X -np.mean(X))/X.std()\n",
    "        self.X1 = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "        self.y = y\n",
    "        self.__train() # Begin training\n",
    "        \n",
    "        \n",
    "    def __predict(self,X_eval):\n",
    "        #return np.dot(W, x_vector)\n",
    "        #return np.matmul(X_eval, self.W.T)\n",
    "        return self.sigmoid(X_eval@self.W.T)\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        return 1.0/(1+np.exp(-z))\n",
    "    \n",
    "    def predict(self, X_temp):\n",
    "        X_temp = (X_temp -np.mean(X_temp))/X_temp.std()\n",
    "        temp  = np.hstack((np.ones((X_temp.shape[0],1)), X_temp))\n",
    "        #print (temp.shape)\n",
    "        return self.__predict(temp)\n",
    "    \n",
    "    def loss_func(self,y, y_hat):\n",
    "        cost = -1*(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
    "        return np.mean(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[:,:-1], np.random.choice([0,1], data.shape[0])\n",
    "model = logistic_reg()\n",
    "model.train(X,y)\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.2 0.3 0.5 0.7 0.7 0.8]\n",
      "[(0.25, 0.0), (0.25, 0.6666666666666666), (0.25, 0.6666666666666666), (0.5, 0.6666666666666666), (0.75, 0.6666666666666666), (0.75, 1.0), (1.0, 1.0)]\n",
      "0.5833333333333333\n",
      "0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Compute AUC; mostly written by me with some help from StackOverflow\n",
    "def give_tpr_fpr(y, y_pred, cutoff):\n",
    "    y_hat = np.where(y_pred >= cutoff, 1, 0)\n",
    "    TP = np.sum((y == 1) & (y_hat == 1))\n",
    "    FP = np.sum((y == 0) & (y_hat == 1))\n",
    "    FN = np.sum((y == 1) & (y_hat == 0))\n",
    "    TN = np.sum((y == 0) & (y_hat == 0))\n",
    "    #print (TP, FP, FN, TN, y_hat)\n",
    "    \n",
    "    tpr = TP/(TP+FN)\n",
    "    fpr = FP/(FP+TN)\n",
    "    return fpr, tpr  \n",
    "\n",
    "def compute_auc(y, y_pred):\n",
    "    thresholds = np.sort(y_pred) # thresholds in ascending order\n",
    "    print(thresholds)\n",
    "    #np.hstack((np.array([0.]), y_pred,np.array([1.]))) # appended 0 and 1 in the end \n",
    "    points = []\n",
    "    for cutoff in thresholds:\n",
    "        point = give_tpr_fpr(y, y_pred, cutoff)\n",
    "        points.append(point)\n",
    "    \n",
    "    points = points[::-1]\n",
    "    print(points)\n",
    "    auc = 0\n",
    "    for i in range(len(points) -1):\n",
    "        dx = points[i+1][0] - points[i][0]\n",
    "        y_avg = (points[i+1][1] + points[i][1])/2\n",
    "        auc += dx*y_avg\n",
    "    return auc\n",
    "\n",
    "y_pred = np.array([0.7, 0.1, 0.5, 0.8, 0.2, 0.7, 0.3])\n",
    "y = np.array([1,0,0,0,1,1,0])\n",
    "print (compute_auc(y, y_pred))\n",
    "### for verification\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_pred)\n",
    "print (metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8, 0.8, 0.7, 0.3, 0.2, 0.1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161.1, 0.9132139995198986)\n",
      "0.9132139995198986\n"
     ]
    }
   ],
   "source": [
    "# Written purely by me after some rial and error \n",
    "def compute_percentile(a, perc):\n",
    "    #perc = 100\n",
    "    a_sorted = np.sort(a)\n",
    "\n",
    "    end = len(a) - 1\n",
    "    start = 0 \n",
    "    index = start + ( end - start)*perc/100\n",
    "    #print (index)\n",
    "    int_index = int(index)\n",
    "    rem_index = index - int_index\n",
    "    next_index = int_index + 1\n",
    "    if next_index == len(a): next_index -= 1 # Just a corner case when perc == 100; else not required\n",
    "    val = a_sorted[int_index] + rem_index*(a_sorted[next_index] - a_sorted[int_index])\n",
    "    return (index, val)\n",
    " \n",
    "# Code for percentile\n",
    "a = np.random.rand(180)\n",
    "#a = [10,20,30,40]\n",
    "print (compute_percentile(a, 90))\n",
    "\n",
    "#compared with actual -- its matching\n",
    "print (np.percentile(a, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 14258, 5: 14248, 3: 14211, 6: 14226, 4: 14381, 1: 14412, 7: 14264})"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate rand7() ; given rand5()\n",
    "# Source - https://leetcode.com/problems/implement-rand10-using-rand7/solution/\n",
    "# Source - https://stackoverflow.com/questions/137783/expand-a-random-range-from-1-5-to-1-7\n",
    "def rand5():\n",
    "    return np.random.choice(5)+1\n",
    "\n",
    "def rand7():\n",
    "    while(True):\n",
    "        row = rand5()\n",
    "        col = rand5()\n",
    "        count = (row -1)*5 + col \n",
    "        if count <= 21:    \n",
    "            return count%7+1\n",
    "Counter([rand7() for _ in range(100000)])\n",
    "\n",
    "# Expected number of calls to rand5() to generate one rand7()\n",
    "# prob of success = 21/25; From geometric distribution: Expected value = 25/21 ; calls = 2*25/21 = 2.38\n",
    "# must watch approach -2 in leetcode ; reduces the wastage to next level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =  [10,20,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 10), (1, 20), (2, 30)]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
