{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aaba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time = 11:08 pm \n",
    "# Build a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35639cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2808dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg:\n",
    "    def __init__(self, lr = 0.01,n_iter = 1000, tol = 1e-5, verbose = False):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def initialize(self, numvar):\n",
    "        self.weights = np.zeros(numvar).reshape(1,-1) # np.random.rand(numvar).reshape(1,-1) # shape = (1,3)\n",
    "        self.bias = np.zeros(1).reshape(1,-1) #np.random.rand(1).reshape(1,1)\n",
    "        if self.verbose: print(self.weights.shape, self.bias.shape)\n",
    "        \n",
    "    def gradient(self, X,Y, Y_pred, flag):\n",
    "        if flag == 'weight':\n",
    "            return (2.0/X.shape[0])* np.matmul((Y_pred- Y).T, X) # shape (1,3)\n",
    "        else:\n",
    "            return (2.0/X.shape[0])*np.sum(Y_pred - Y)\n",
    "        \n",
    "    def compute_loss(self,Y, Y_pred):\n",
    "        #return (1.0/X.shape[0])*np.sum((Y-Y_pred)**2)\n",
    "        return np.mean((Y-Y_pred)**2)\n",
    "    \n",
    "    def train(self,X,Y):\n",
    "        self.initialize(X.shape[1])\n",
    "        \n",
    "        prev_loss = 0\n",
    "        for iter_num in range(self.n_iter):\n",
    "            Y_pred = self.predict(X)\n",
    "            if self.verbose: print (\"Y_pred.shape: \", Y_pred.shape)\n",
    "            loss = self.compute_loss(Y,Y_pred)\n",
    "            self.weights -= self.lr*self.gradient(X,Y, Y_pred, \"weight\")\n",
    "            self.bias -= self.lr*self.gradient(X,Y, Y_pred, \"bias\")\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                break\n",
    "            if self.verbose: print (iter_num, loss)\n",
    "            prev_loss = loss\n",
    "        if self.verbose: print(self.weights, self.bias)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.matmul(X,self.weights.T) + self.bias # shape = 100*3, 3*1 = 100,1 + 1 = 100,1\n",
    "    \n",
    "    def rmse(self, Y, Y_pred):\n",
    "        return (1.0/X.shape[0])*np.sum(np.power(Y-Y_pred, 2))**0.5\n",
    "    \n",
    "    def rsquare(self,Y,Y_pred):\n",
    "        avg_model = np.mean(Y)\n",
    "        rmse_avg_model = self.rmse(Y, avg_model)\n",
    "        rmse = self.rmse(Y, Y_pred)\n",
    "        r2 = 1 - rmse/rmse_avg_model\n",
    "        return r2\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c323f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.random.rand(1000,2)\n",
    "X = np.arange(0,10, 0.005).reshape(-1,1)\n",
    "Y = X*3 -5 + np.random.randn(X.shape[0], X.shape[1])*3\n",
    "\n",
    "train_mean = np.mean(X, axis = 0)\n",
    "train_std = np.std(X, axis = 0)\n",
    "X = (X - train_mean)/train_std\n",
    "#X = np.random.rand(1000,2)\n",
    "#Y = np.random.rand(1000,1)*10\n",
    "\n",
    "X_test = np.arange(0,10, 0.003).reshape(-1,1)\n",
    "Y_test = X_test*3 -5 + np.random.randn(X_test.shape[0], X_test.shape[1])*3\n",
    "\n",
    "X_test = (X_test - train_mean)/train_std\n",
    "\n",
    "print (X.shape, Y.shape)\n",
    "#print (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54979a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearReg(verbose = True)\n",
    "linreg.train(X,Y)\n",
    "Y_pred = linreg.predict(X)\n",
    "Y_pred_test = linreg.predict(X_test)\n",
    "#print (Y_pred)\n",
    "print (\"Training data metrics: \", linreg.rmse(Y,Y_pred),linreg.rmse(Y,np.mean(Y)), linreg.rsquare(Y,Y_pred))\n",
    "print (\"Test data metrics: \", linreg.rmse(Y_test,Y_pred_test),linreg.rmse(Y_test,np.mean(Y_test)), linreg.rsquare(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:100],Y[:100])\n",
    "plt.scatter(X[:100],Y_pred[:100], color = 'red')\n",
    "#plt.scatter(X_test[:100],Y_pred_test[:100], color = 'green')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Scatter Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1899e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logreg:\n",
    "    def __init__(self, lr = 0.001,n_iter = 1000, tol = 1e-5, verbose = False):\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def initialize(self, numvar):\n",
    "        self.weights = np.zeros(numvar).reshape(1,-1) # np.random.rand(numvar).reshape(1,-1) # shape = (1,3)\n",
    "        self.bias = np.zeros(1).reshape(1,-1) #np.random.rand(1).reshape(1,1)\n",
    "        if self.verbose: print(\"Parameter shapes: \", self.weights.shape, self.bias.shape)\n",
    "        \n",
    "    def gradient(self, X,Y, Y_pred, flag):\n",
    "        if self.verbose: print(\"In gradient: \", X.shape, Y.shape, Y_pred.shape)\n",
    "        if flag == 'weight':\n",
    "            return (2.0/X.shape[0])* np.matmul((Y_pred- Y).T, X) # shape (1,3)\n",
    "        else:\n",
    "            return (2.0/X.shape[0])*np.sum(Y_pred - Y)\n",
    "        \n",
    "    def compute_loss(self,Y, Y_pred):\n",
    "        l = -Y*np.log(Y_pred) - (1-Y)*np.log(1-Y_pred)\n",
    "        return np.mean(l)\n",
    "    \n",
    "    def train(self,X,Y):\n",
    "        self.initialize(X.shape[1])\n",
    "        \n",
    "        prev_loss = 0\n",
    "        for iter_num in range(self.n_iter):\n",
    "            Y_pred = self.predict(X)\n",
    "            if self.verbose: print (\"In Train: Y_pred.shape: \", Y_pred.shape)\n",
    "            loss = self.compute_loss(Y,Y_pred)\n",
    "            self.weights -= self.lr*self.gradient(X,Y, Y_pred, \"weight\")\n",
    "            self.bias -= self.lr*self.gradient(X,Y, Y_pred, \"bias\")\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                break\n",
    "            if self.verbose: print (iter_num, loss)\n",
    "            prev_loss = loss\n",
    "        if self.verbose: print(self.weights, self.bias)\n",
    "            \n",
    "    def sigmoid(self,X):\n",
    "        return 1.0/(1.0 + np.exp(-X))\n",
    "    \n",
    "    def predict(self,X):\n",
    "        Z = np.matmul(X,self.weights.T) + self.bias # shape = 100*3, 3*1 = 100,1 + 1 = 100,1\n",
    "        if self.verbose: print (\"In Predict: \", Z.shape)\n",
    "        return self.sigmoid(Z)\n",
    "        \n",
    "    def accuracy(self, Y, Y_prob, threshold  = 0.5):\n",
    "        Y_pred = np.where(Y_prob > threshold, 1, 0).reshape(-1,1)\n",
    "        return sum(Y==Y_pred)/len(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.random.rand(1000,3) + 1\n",
    "#Y = np.mean(X, axis = 1) > 1.5 \n",
    "#Y = np.where(Y==True, 1,0).reshape(-1,1)\n",
    "\n",
    "\n",
    "n = 10000\n",
    "X_data,Y_data = make_classification(n_samples=n, n_features=5)\n",
    "Y_data = Y_data.reshape(-1,1)\n",
    "\n",
    "X,Y = X_data[:int(n*0.8)], Y_data[:int(n*0.8)]\n",
    "X_test,Y_test = X_data[int(n*0.8):], Y_data[int(n*0.8):]\n",
    "\n",
    "\n",
    "\n",
    "train_mean = np.mean(X, axis = 0)\n",
    "train_std = np.std(X, axis = 0)\n",
    "X = (X - train_mean)/train_std\n",
    "\n",
    "#X_test = np.random.rand(1000,3) + 1\n",
    "#Y_test = np.mean(X_test, axis = 1) > 1.5\n",
    "#Y_test = np.where(Y_test==True, 1,0).reshape(-1,1)\n",
    "\n",
    "X_test = (X_test - train_mean)/train_std\n",
    "\n",
    "logreg = Logreg(verbose = False)\n",
    "logreg.train(X,Y)\n",
    "Y_prob = logreg.predict(X)\n",
    "#print (\"Y_pred: \", Y_pred)\n",
    "Y_prob_test = logreg.predict(X_test)\n",
    "\n",
    "#print (Y_pred)\n",
    "print (\"Training data metrics: \", logreg.accuracy(Y,Y_prob))\n",
    "print (\"Test data metrics: \", logreg.accuracy(Y_test,Y_prob_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with Logistic Regression from SKLEARN\n",
    "clf = LogisticRegression(random_state=0).fit(X,Y.reshape(-1))\n",
    "Y_prob = clf.predict_proba(X)[:,1]\n",
    "Y_prob_test = clf.predict_proba(X_test)[:,1]\n",
    "print (Y.shape, Y_prob.shape)\n",
    "print (\"Training data metrics: \", logreg.accuracy(Y,Y_prob))\n",
    "print (\"Test data metrics: \", logreg.accuracy(Y_test,Y_prob_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Percentile ##\n",
    "# Given a list of numbers, return the value of say 10% percentile\n",
    "\n",
    "a = [10,20,25,30,45,50,89]\n",
    "x =0.25\n",
    "\n",
    "start = 0; end = len(a) - 1\n",
    "index = start + (end - start)*x\n",
    "\n",
    "index_whole = int(index)\n",
    "index_rem = index - index_whole\n",
    "\n",
    "if index_whole != end:\n",
    "    res = a[index_whole] + (a[index_whole+1] - a[index_whole])*index_rem\n",
    "else:\n",
    "    res = a[index_whole]\n",
    "print (res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ead54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coding a Decision Tree ## # Start time= 5:30 PM\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feat_id = None, threshold = None, is_leaf = False, left = None, right = None, y_pred = None):\n",
    "        self.feat_id = feat_id\n",
    "        self.threshold = threshold\n",
    "        self.is_leaf = is_leaf\n",
    "        self.y_pred = y_pred\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.root = None\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self,max_depth = 5, verbose = False):\n",
    "        self.max_depth = max_depth\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def entropy(self, y):\n",
    "        '''\n",
    "        Shape of Y is (n,) & Y is binary 0/1\n",
    "        '''\n",
    "        n = y.shape[0]\n",
    "        num_1 = np.where(y == 1)[0].shape[0]\n",
    "        num_0 = np.where(y == 0)[0].shape[0]\n",
    "        p_1 = num_1/n\n",
    "        p_0 = num_0/n\n",
    "        if p_0 in [1.0, 0.0]:\n",
    "            return 0\n",
    "        ent = -p_0*np.log(p_0) - p_1*np.log(p_1)\n",
    "        return ent\n",
    "    \n",
    "    def gain(self, Xcol, y):\n",
    "        '''\n",
    "        Xcol shape = (n,) ; y shape = (n,)\n",
    "        Assuming Xcol is continuos and we are splitting on median\n",
    "        '''\n",
    "        nrow = Xcol.shape[0]\n",
    "        if self.verbose:\n",
    "            print (\"Inside Gain: \", Xcol.shape, y.shape)\n",
    "        \n",
    "        threshold = np.median(Xcol)\n",
    "        indices1 = np.where(Xcol > threshold)\n",
    "        indices2 = np.where(Xcol <= threshold)\n",
    "        y1 = y[indices1]\n",
    "        y2 = y[indices2]\n",
    "        w1 = len(indices1)/nrow\n",
    "        w2 = 1 - w1\n",
    "        \n",
    "        g = self.entropy(y) - w1*self.entropy(y1) - w2*self.entropy(y2)\n",
    "        return g, threshold, indices1, indices2\n",
    "        \n",
    "    def select_feature(self, X,y):\n",
    "        nrow, ncol = X.shape\n",
    "        if self.verbose: print (X.shape)\n",
    "            \n",
    "        max_gain = -float(\"inf\"); best_feat_id = None; best_threshold = None; best_indices1 = None; best_indices2 = None\n",
    "        for feat_id in range(ncol):\n",
    "            cur_gain, threshold, indices1, indices2 = self.gain(X[:,feat_id], y)\n",
    "            if cur_gain > max_gain:\n",
    "                max_gain = cur_gain\n",
    "                best_feat_id = feat_id\n",
    "                best_threshold = threshold\n",
    "                best_indices1 = indices1\n",
    "                best_indices2 = indices2 \n",
    "                \n",
    "                \n",
    "        return best_feat_id, max_gain, best_threshold, best_indices1, best_indices2\n",
    "            \n",
    "        \n",
    "    def _build(self, X,y, cur_depth):\n",
    "        \n",
    "        num_1 = len(np.where(y == 1)[0])\n",
    "        num_0 = len(np.where(y == 0)[0])\n",
    "        \n",
    "        if cur_depth >= self.max_depth or num_1 == len(y) or num_0 == len(y):\n",
    "            y_pred = int(num_1 > num_0)\n",
    "            if self.verbose: print(\"inside build: \", y, num_1, num_0)\n",
    "            return Node(is_leaf = True, y_pred = y_pred)\n",
    "        \n",
    "        best_feat_id, max_gain, best_threshold, best_indices1, best_indices2 = self.select_feature(X,y)\n",
    "        X_left = X[best_indices1]\n",
    "        X_right = X[best_indices2]\n",
    "        y_left = y[best_indices1]\n",
    "        y_right = y[best_indices2]\n",
    "        \n",
    "        root = Node(feat_id = best_feat_id, threshold = best_threshold)\n",
    "        root.left = self._build(X_left, y_left, cur_depth+1)\n",
    "        root.right = self._build(X_right, y_right, cur_depth+1)\n",
    "        \n",
    "        return root \n",
    "    \n",
    "    def train(self,X,y):\n",
    "        self.root = self._build(X,y, 0)\n",
    "        \n",
    "    def test(self, X):\n",
    "        Y_pred = []\n",
    "        for x in X:\n",
    "            Y_pred.append(self.predict(x))\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    def predict(self, x):\n",
    "        curr = self.root \n",
    "        while(curr.is_leaf == False):\n",
    "            if x[curr.feat_id] > curr.threshold: # Left \n",
    "                curr = curr.left\n",
    "            else:\n",
    "                curr = curr.right\n",
    "        if self.verbose: print (\"Inside Predict: \", curr.is_leaf, curr.y_pred)\n",
    "        return curr.y_pred\n",
    "    \n",
    "    def accuracy(self, y, y_pred):\n",
    "        return sum(y == y_pred)/len(y)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706399e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(10000,3)\n",
    "#y = np.random.randint(0,2,1000)\n",
    "\n",
    "y = np.where(np.mean(X, axis = 1) > 0.6 + np.random.rand()*0.3 ,1,0)\n",
    "\n",
    "X_test = np.random.rand(1000,3)\n",
    "y_test = np.where(np.mean(X_test, axis = 1) > 0.6+ np.random.rand()*0.3 ,1,0)\n",
    "\n",
    "print (X.shape, y.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTree(verbose = False)\n",
    "DT.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = DT.test(X)\n",
    "y_pred = DT.test(X_test)\n",
    "print (\"Train Accuracy: \", DT.accuracy(y_pred, y_test))\n",
    "print (\"Test Accuracy: \", DT.accuracy(y_pred_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0, max_depth = 5, criterion='entropy')\n",
    "clf.fit(X,y)\n",
    "y_pred_train = clf.predict(X)\n",
    "y_pred = clf.predict(X_test)\n",
    "print (\"Train Accuracy: \", DT.accuracy(y_pred, y_test))\n",
    "print (\"Test Accuracy: \", DT.accuracy(y_pred_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printtree(curr):\n",
    "    if curr:\n",
    "        #print(curr.feat_id, curr.threshold, curr.is_leaf, curr.y_pred)\n",
    "        if curr.is_leaf:\n",
    "            pass\n",
    "            #print(curr.feat_id, curr.threshold, curr.is_leaf, curr.y_pred)\n",
    "        else:\n",
    "            printtree(curr.left)\n",
    "            printtree(curr.right)\n",
    "printtree(DT.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4552f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees =10,verbose = True, max_features = None):\n",
    "        self.verbose = verbose\n",
    "        self.n_trees = n_trees\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "    \n",
    "    def get_data_for_tree(self, X,y):\n",
    "        # Random Sampling with replacement for rows \n",
    "        # Random Sampling without replacement for features\n",
    "        nrow, nfeat = X.shape\n",
    "        if self.verbose: print (X.shape, y.shape, self.max_features)\n",
    "        chosen_feat_id = np.random.choice(range(nfeat), self.max_features)\n",
    "        X_with_chosen_feats = X[:,chosen_feat_id]\n",
    "        \n",
    "        #chosen_row_id = np.array([np.random.randint(nrow) for _ in range(nrow)])\n",
    "        chosen_row_id = np.random.choice(range(nrow), nrow , replace = True)\n",
    "        X_filtered = X[chosen_row_id]\n",
    "        y_filtered = y[chosen_row_id]\n",
    "        \n",
    "        return X_filtered, y_filtered\n",
    "        \n",
    "    \n",
    "    def train(self, X,y):\n",
    "        self.max_features = min(2, int(np.sqrt(X.shape[1])))\n",
    "        \n",
    "        for tree_num in range(self.n_trees):\n",
    "            X_tree, y_tree = self.get_data_for_tree(X,y)\n",
    "            DT = DecisionTree()\n",
    "            DT.train(X_tree, y_tree)\n",
    "            self.trees.append(DT)\n",
    "    \n",
    "    def test(self, X):\n",
    "        Y_pred = []\n",
    "        for x in X:\n",
    "            Y_pred.append(self.predict(x))\n",
    "        return np.array(Y_pred)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        res = np.array([dt.predict(x) for dt in self.trees])\n",
    "        num_1 = len(np.where(y == 1)[0])\n",
    "        num_0 = len(np.where(y == 0)[0])\n",
    "        \n",
    "        return int(num_1 > num_0)\n",
    "    \n",
    "    def accuracy(self, y, y_pred):\n",
    "        return sum(y == y_pred)/len(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57556100",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForest(verbose = True)\n",
    "RF.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63dc4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = RF.test(X)\n",
    "y_pred = RF.test(X_test)\n",
    "\n",
    "print (\"Train Accuracy: \", RF.accuracy(y_pred, y_test))\n",
    "print (\"Test Accuracy: \", RF.accuracy(y_pred_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Kmeans Clustering Class -- Start TIme = 7 : 50 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f84858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, k, n_iter = 30 , init_method = 'random' ,verbose = False, random_state = False):\n",
    "        if k <=1:\n",
    "            raise ValueError(\"k cannot be less than 2\")\n",
    "        self.k = k \n",
    "        self.n_iter = n_iter\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "        self.init_method = init_method \n",
    "        \n",
    "    \n",
    "    def param_init(self, X):\n",
    "        '''\n",
    "        Shape of X = (nrows, d )\n",
    "        return k cluster centroids\n",
    "        '''\n",
    "        nrow, d = X.shape\n",
    "        indices = list(range(nrow))\n",
    "        \n",
    "        if self.random_state != False:\n",
    "            np.random.seed(self.random_state)\n",
    "        chosen_indices = np.random.choice(indices, self.k)\n",
    "        return X[chosen_indices]\n",
    "    \n",
    "    \n",
    "    def get_new_centroid(self, X, centroids):\n",
    "        max_dists =[]\n",
    "        for point in X:\n",
    "            dists = [self.distance(point, centroid) for centroid in centroids]\n",
    "            max_dists.append(np.min(dists))\n",
    "        return X[np.argmax(max_dists)]\n",
    "        \n",
    "    \n",
    "    def param_init_smart(self,X):\n",
    "        nrow, d= X.shape\n",
    "        index = np.random.randint(0,nrow)\n",
    "        print (\"Inside param init smart: \", index)\n",
    "        centroids = [X[index]]\n",
    "        for i in range(1,self.k):\n",
    "            centroid = self.get_new_centroid(X, centroids)\n",
    "            centroids.append(centroid)\n",
    "        return np.array(centroids)\n",
    "        \n",
    "    \n",
    "    def compute_centroid(self, X, cluster_assignment):\n",
    "        '''\n",
    "        Recomputes centroid given a cluster_assignment\n",
    "        '''\n",
    "        \n",
    "        nrow, d = X.shape\n",
    "        centroids = []\n",
    "        for cluster_id in range(self.k):\n",
    "            indices = np.where(cluster_assignment == cluster_id)\n",
    "            X_cluster = X[indices]\n",
    "            centroids.append(np.mean(X_cluster, axis = 0))\n",
    "        return centroids\n",
    "            \n",
    "    \n",
    "    def assign_cluster(self, X, centroids):\n",
    "        '''\n",
    "        Assign ClusterID to each point given centroids\n",
    "        '''\n",
    "        nrow, d = X.shape\n",
    "        cluster_assignment = []\n",
    "        for point in X:\n",
    "            assigned_cluster_id = np.argmin([self.distance(point, centroid) for centroid in centroids])\n",
    "            cluster_assignment.append(assigned_cluster_id)\n",
    "        return np.array(cluster_assignment)\n",
    "    \n",
    "    def distance(self, a,b):\n",
    "        '''\n",
    "        Shape of a = (d,) & shape of b = (d, )\n",
    "        ''' \n",
    "        return np.sum((a - b)**2)**0.5\n",
    "    \n",
    "    def fit(self, X):\n",
    "        if self.init_method =='kmeans++':\n",
    "            centroids = self.param_init_smart(X)\n",
    "        else:\n",
    "            centroids = self.param_init(X)\n",
    "        \n",
    "        prev_clus_assignment = np.zeros(X.shape[0])\n",
    "        for iterno in range(self.n_iter):\n",
    "            cluster_assignment = self.assign_cluster(X, centroids) \n",
    "            if self.verbose: print (\"Inside Fit: \", cluster_assignment)\n",
    "            if np.all(cluster_assignment == prev_clus_assignment):\n",
    "                    if self.verbose or True: print (\"Exiting Iterations early\", iterno)\n",
    "                    break\n",
    "            #else:\n",
    "            centroids = self.compute_centroid(X, cluster_assignment)\n",
    "            prev_clus_assignment = cluster_assignment\n",
    "        self.centroids= centroids\n",
    "        self.cluster_assignment = cluster_assignment\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Shape of X = (n, d)\n",
    "        '''\n",
    "        return self.assign_cluster(X, self.centroids) \n",
    "        \n",
    "    def norm_sse(self, X):\n",
    "        '''\n",
    "        SSE = Sum of squared errors for each cluster\n",
    "        norm_see = SSE/ SSE if k = 1 \n",
    "        '''\n",
    "        \n",
    "        SSE = 0\n",
    "        \n",
    "        for cluster_id in range(self.k):\n",
    "            indices = np.where(self.cluster_assignment == cluster_id)\n",
    "            X_cluster = X[indices]\n",
    "            SSE += np.sum([self.distance(point, self.centroids[cluster_id])**2 for point in X_cluster])\n",
    "        \n",
    "        SSE_1_cluster = np.sum([self.distance(point, np.mean(X))**2 for point in X])\n",
    "        return SSE/SSE_1_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Some data for Clustering\n",
    "X1 = 2*np.random.randn(100, 2) + 20\n",
    "X2 = -3*np.random.randn(120,2) - 10\n",
    "X3 = np.random.randn(100,2) + 1\n",
    "\n",
    "X = np.vstack((X1, X2, X3))\n",
    "\n",
    "X_mean = np.mean(X, axis = 0)\n",
    "X_std = np.std(X, axis = 0)\n",
    "X = (X - X_mean)/ X_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    km = KMeans(k = 3, verbose = False, random_state = False, init_method ='kmeans++')\n",
    "    km.fit(X)\n",
    "    print (\"SSE: \", km.norm_sse(X))\n",
    "    print (\"centers: \", km.centroids)\n",
    "    #km.predict(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the point with cluster \n",
    "colors = ['red', 'green', 'blue']\n",
    "c = [colors[i] for i in km.cluster_assignment]\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c = c)\n",
    "plt.xlabel(\"Feature1\")\n",
    "plt.ylabel(\"Feature2\")\n",
    "plt.title(\"Kmeans Clustering Example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Elbow Curve\n",
    "SSE_list = []; k_val = []\n",
    "for k in range(2,10):\n",
    "    km = KMeans(k = k, verbose = False)\n",
    "    km.fit(X)\n",
    "    SSE = km.norm_sse(X)\n",
    "    SSE_list.append(SSE)\n",
    "    k_val.append(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733af7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_val, SSE_list, 'o-')\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"sse\")\n",
    "plt.title(\"Kmeans Elbow Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,0,1])\n",
    "b = np.array([1,0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34604ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class kfold:\n",
    "    def __init__(self, n_splits = 5, shuffle = False, random_seed = False, verbose = False):\n",
    "             self.n_splits = n_splits\n",
    "             if n_splits <= 1:\n",
    "                     raise ValueError(\"num of splits shoud be > 1 and <= number of rows\")\n",
    "             self.shuffle = shuffle\n",
    "             self.random_seed = random_seed\n",
    "             self.verbose = verbose\n",
    "         \n",
    "    def split(self, X,y):\n",
    "        '''\n",
    "        Input: X ( Shape = (n,d) ); y (shape = (n,))\n",
    "        '''\n",
    "        nrow, n_feat = X.shape\n",
    "        indices = np.array(range(nrow))\n",
    "        if self.shuffle:\n",
    "            if self.random_seed != False:\n",
    "                np.random.seed(self.random_seed)\n",
    "            random.shuffle(indices)\n",
    "            \n",
    "        num_of_rows_divisible = len(indices) - len(indices)%self.n_splits\n",
    "        #leftover_indices_count = len(indices)%self.n_splits\n",
    "        \n",
    "        indices_splitted = np.split(indices[:num_of_rows_divisible], self.n_splits)\n",
    "        indices_leftover = np.array(indices[num_of_rows_divisible:])\n",
    "        if self.verbose: print (\"indices spltited: \", indices_splitted)\n",
    "        if self.verbose: print (\"indices_leftover: \", indices_leftover)\n",
    "        \n",
    "        res = []\n",
    "        for splitnum in range(self.n_splits):\n",
    "            if splitnum >= len(indices_leftover):\n",
    "                chosen_indices = indices_splitted[splitnum]\n",
    "            else:\n",
    "                chosen_indices = np.append(indices_splitted[splitnum], indices_leftover[splitnum])\n",
    "            mask = np.array([True if i in set(chosen_indices) else False for i in range(nrow) ])\n",
    "            X_train = X[~mask]\n",
    "            y_train = y[~mask]\n",
    "            X_test = X[mask]\n",
    "            y_test = y[mask]\n",
    "            res.append([X_train, y_train, X_test, y_test])\n",
    "        \n",
    "        return res\n",
    "\n",
    "def accuracy(y_true, y_prob, threshold= 0.5):\n",
    "    y_pred = np.where(y_prob > threshold, 1, 0)\n",
    "    acc = np.sum(y_pred == y_true)/len(y_true)\n",
    "    return acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9488bed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8001, 5) (8001,) (2001, 5) (2001,)\n",
      "(8001, 5) (8001,) (2001, 5) (2001,)\n",
      "(8002, 5) (8002,) (2000, 5) (2000,)\n",
      "(8002, 5) (8002,) (2000, 5) (2000,)\n",
      "(8002, 5) (8002,) (2000, 5) (2000,)\n",
      "0.9214156421789106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#X = np.random.rand(1002,3)\n",
    "#y = np.random.randint(0,2, 1002)\n",
    "\n",
    "n = 10002\n",
    "X,y = make_classification(n, 5)\n",
    "\n",
    "kf = kfold(5, verbose = False, shuffle = True)\n",
    "\n",
    "acc_list = []\n",
    "for X_train, y_train, X_test, y_test in kf.split(X,y):\n",
    "    print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    #print (y_pred)\n",
    "    acc = accuracy(y_test, y_prob[:,1])\n",
    "    acc_list.append(acc)\n",
    "\n",
    "print (np.mean(acc_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52848347",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 11\n",
    "indices = np.array(range(nrow))\n",
    "num_of_rows_divisible = len(indices) - len(indices)%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_splitted = np.split(indices[:num_of_rows_divisible], 3)\n",
    "indices_leftover = np.array(indices[num_of_rows_divisible:])\n",
    "print (indices_splitted, indices_leftover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39549f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitnum = 2\n",
    "np.append(indices_splitted[splitnum], indices_leftover[splitnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b4b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
